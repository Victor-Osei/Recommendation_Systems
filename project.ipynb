{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from implicit.als import AlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2756101 entries, 0 to 2756100\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   timestamp      int64  \n",
      " 1   visitorid      int64  \n",
      " 2   event          object \n",
      " 3   itemid         int64  \n",
      " 4   transactionid  float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 105.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "        timestamp  visitorid event  itemid  transactionid\n",
       " 0  1433221332117     257597  view  355908            NaN\n",
       " 1  1433224214164     992329  view  248676            NaN\n",
       " 2  1433221999827     111016  view  318965            NaN\n",
       " 3  1433221955914     483717  view  253185            NaN\n",
       " 4  1433221337106     951259  view  367447            NaN)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File path\n",
    "events_path = \"events.csv\"\n",
    "\n",
    "# Load the events.csv file\n",
    "events_df = pd.read_csv(events_path)\n",
    "\n",
    "# Display basic info and first few rows\n",
    "events_df.info(), events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Unix timestamp into a readable date/time format\n",
    "events_df['datetime'] = pd.to_datetime(events_df['timestamp'], unit='ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event\n",
       "view           2664312\n",
       "addtocart        69332\n",
       "transaction      22457\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many events of each type exist \n",
    "events_df['event'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407580"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique visitors there are.\n",
    "events_df['visitorid'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp              0\n",
       "visitorid              0\n",
       "event                  0\n",
       "itemid                 0\n",
       "transactionid    2733644\n",
       "datetime               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "visitorid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "event",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "itemid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "transactionid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "78b3a3b0-b989-4f0a-aef2-65df9cc19903",
       "rows": [
        [
         "0",
         "1433221332117",
         "257597",
         "view",
         "355908",
         null,
         "2015-06-02 05:02:12.117000"
        ],
        [
         "1",
         "1433224214164",
         "992329",
         "view",
         "248676",
         null,
         "2015-06-02 05:50:14.164000"
        ],
        [
         "2",
         "1433221999827",
         "111016",
         "view",
         "318965",
         null,
         "2015-06-02 05:13:19.827000"
        ],
        [
         "3",
         "1433221955914",
         "483717",
         "view",
         "253185",
         null,
         "2015-06-02 05:12:35.914000"
        ],
        [
         "4",
         "1433221337106",
         "951259",
         "view",
         "367447",
         null,
         "2015-06-02 05:02:17.106000"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-02 05:02:12.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-02 05:50:14.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-02 05:13:19.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-02 05:12:35.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-02 05:02:17.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid event  itemid  transactionid  \\\n",
       "0  1433221332117     257597  view  355908            NaN   \n",
       "1  1433224214164     992329  view  248676            NaN   \n",
       "2  1433221999827     111016  view  318965            NaN   \n",
       "3  1433221955914     483717  view  253185            NaN   \n",
       "4  1433221337106     951259  view  367447            NaN   \n",
       "\n",
       "                 datetime  \n",
       "0 2015-06-02 05:02:12.117  \n",
       "1 2015-06-02 05:50:14.164  \n",
       "2 2015-06-02 05:13:19.827  \n",
       "3 2015-06-02 05:12:35.914  \n",
       "4 2015-06-02 05:02:17.106  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View → Add to Cart Conversion Rate: 2.69%\n",
      "Add to Cart → Purchase Conversion Rate: 31.07%\n",
      "Number of potential bot users: 12712\n",
      "           num_addtocart  num_transaction  num_view  total_events\n",
      "visitorid                                                        \n",
      "1150086              719              559      6479          7757\n",
      "530559               419              286      3623          4328\n",
      "152963               371              349      2304          3024\n",
      "895999                56               50      2368          2474\n",
      "163561               124               92      2194          2410\n",
      "371606               110               94      2141          2345\n",
      "286616               120               75      2057          2252\n",
      "684514               231              189      1826          2246\n",
      "892013                 1                0      2023          2024\n",
      "861299               230              188      1573          1991\n"
     ]
    }
   ],
   "source": [
    "# # Load the events data\n",
    "# events_df = pd.read_csv(\"events.csv\")\n",
    "\n",
    "# # Convert timestamp to datetime format\n",
    "# events_df['datetime'] = pd.to_datetime(events_df['timestamp'], unit='ms')\n",
    "\n",
    "# Count event types per user\n",
    "user_events = events_df.pivot_table(index='visitorid', columns='event', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_events.columns = ['num_addtocart', 'num_transaction', 'num_view']\n",
    "\n",
    "# Add a total event count\n",
    "user_events['total_events'] = user_events.sum(axis=1)\n",
    "\n",
    "# Step 1.2: Calculate conversion rates\n",
    "total_views = len(user_events[user_events['num_view'] > 0])\n",
    "total_addtocart = len(user_events[user_events['num_addtocart'] > 0])\n",
    "total_transactions = len(user_events[user_events['num_transaction'] > 0])\n",
    "\n",
    "view_to_cart_rate = (total_addtocart / total_views) * 100\n",
    "cart_to_purchase_rate = (total_transactions / total_addtocart) * 100\n",
    "\n",
    "print(f\"View → Add to Cart Conversion Rate: {view_to_cart_rate:.2f}%\")\n",
    "print(f\"Add to Cart → Purchase Conversion Rate: {cart_to_purchase_rate:.2f}%\")\n",
    "\n",
    "# Step 1.3: Time difference between events for each user\n",
    "events_df.sort_values(by=['visitorid', 'datetime'], inplace=True)\n",
    "events_df['time_diff'] = events_df.groupby('visitorid')['datetime'].diff().dt.total_seconds()\n",
    "\n",
    "# Step 2: Detecting Bots (Anomaly Detection)\n",
    "# Define a threshold (e.g., users with extremely high event counts)\n",
    "threshold = user_events['total_events'].quantile(0.99)  # Top 1% most active users\n",
    "\n",
    "# Identify potential bot users\n",
    "bot_users = user_events[user_events['total_events'] > threshold]\n",
    "\n",
    "print(f\"Number of potential bot users: {len(bot_users)}\")\n",
    "\n",
    "# Show the top 10 bot-like users\n",
    "print(bot_users.sort_values(by='total_events', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bots detected: 16694\n",
      "Remaining users after bot removal: 1390886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Load data\n",
    "# events_df = pd.read_csv(\"events.csv\")\n",
    "# events_df['datetime'] = pd.to_datetime(events_df['timestamp'], unit='ms')\n",
    "\n",
    "# Step 1: Aggregate User Data\n",
    "user_events = events_df.pivot_table(index='visitorid', columns='event', aggfunc='size', fill_value=0)\n",
    "user_events.columns = ['num_addtocart', 'num_transaction', 'num_view']\n",
    "user_events['total_events'] = user_events.sum(axis=1)\n",
    "\n",
    "# Step 2: Identify Bots Based on Activity Threshold\n",
    "event_threshold = user_events['total_events'].quantile(0.99)  # Top 1% users\n",
    "bots_rule_based = user_events[user_events['total_events'] > event_threshold]\n",
    "\n",
    "# Step 3: Calculate Time Differences per User\n",
    "events_df.sort_values(by=['visitorid', 'datetime'], inplace=True)\n",
    "events_df['time_diff'] = events_df.groupby('visitorid')['datetime'].diff().dt.total_seconds()\n",
    "mean_time_diff = events_df.groupby('visitorid')['time_diff'].mean()\n",
    "\n",
    "# Step 4: Apply Isolation Forest for Anomaly Detection\n",
    "features = user_events[['num_addtocart', 'num_transaction', 'num_view', 'total_events']]\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "user_events['anomaly_score'] = iso_forest.fit_predict(features)\n",
    "\n",
    "# Step 5: Merge Time Difference Data\n",
    "user_events = user_events.merge(mean_time_diff, on='visitorid', how='left')\n",
    "\n",
    "# Step 6: Define Final Bot Users\n",
    "bot_users = user_events[(user_events['anomaly_score'] == -1) | (user_events['total_events'] > event_threshold)]\n",
    "print(f\"Number of bots detected: {len(bot_users)}\")\n",
    "\n",
    "# Step 7: Filter Out Bots\n",
    "cleaned_events_df = events_df[~events_df['visitorid'].isin(bot_users.index)]\n",
    "print(f\"Remaining users after bot removal: {cleaned_events_df['visitorid'].nunique()}\")\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_events_df.to_csv(\"cleaned_events.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing item_properties.csv (part1 and 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean and merge the item_properties_part1.1.csv and item_properties_part2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item properties preprocessing complete! 🚀\n"
     ]
    }
   ],
   "source": [
    "# Load both item properties files\n",
    "item_properties_1 = pd.read_csv(\"item_properties_part1.1.csv\")\n",
    "item_properties_2 = pd.read_csv(\"item_properties_part2.csv\")\n",
    "\n",
    "# Merge the two parts into one DataFrame\n",
    "item_properties = pd.concat([item_properties_1, item_properties_2])\n",
    "\n",
    "# Convert timestamp to readable format\n",
    "item_properties['datetime'] = pd.to_datetime(item_properties['timestamp'], unit='ms')\n",
    "\n",
    "# Keep only the latest property value for each item\n",
    "item_properties = item_properties.sort_values(by=['itemid', 'datetime']).drop_duplicates(subset=['itemid'], keep='last')\n",
    "\n",
    "# Filter for category and availability\n",
    "item_properties_filtered = item_properties[item_properties['property'].isin(['categoryid', 'available'])]\n",
    "\n",
    "# Pivot the data so that each item has categoryid & available columns\n",
    "item_properties_pivot = item_properties_filtered.pivot(index='itemid', columns='property', values='value').reset_index()\n",
    "\n",
    "# Convert availability to integer (0 or 1)\n",
    "item_properties_pivot['available'] = item_properties_pivot['available'].astype(float).fillna(0).astype(int)\n",
    "\n",
    "# Save cleaned dataset\n",
    "item_properties_pivot.to_csv(\"cleaned_item_properties.csv\", index=False)\n",
    "\n",
    "print(\"Item properties preprocessing complete! 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User viewed item 30391 in category nan.\n",
      "Recommended items from the same category: []\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned item properties\n",
    "item_properties = pd.read_csv(\"cleaned_item_properties.csv\")\n",
    "\n",
    "# Load cleaned events data (after bot removal)\n",
    "events_df = pd.read_csv(\"cleaned_events.csv\")\n",
    "\n",
    "# Merge events with item properties to include category information\n",
    "events_df = events_df.merge(item_properties, on='itemid', how='left')\n",
    "\n",
    "# Filter out unavailable products\n",
    "events_df = events_df[events_df['available'] == 1]\n",
    "\n",
    "# Step 1: Identify most viewed & purchased products per category\n",
    "popular_items = events_df.groupby(['categoryid', 'itemid'])['event'].count().reset_index()\n",
    "popular_items = popular_items.sort_values(by=['categoryid', 'event'], ascending=[True, False])\n",
    "\n",
    "# Step 2: Define a recommendation function\n",
    "def recommend_items(categoryid, exclude_itemid=None, num_recommendations=5):\n",
    "    \"\"\" Recommend top N items from the same category, excluding the current item \"\"\"\n",
    "    recommendations = popular_items[popular_items['categoryid'] == categoryid]\n",
    "    if exclude_itemid:\n",
    "        recommendations = recommendations[recommendations['itemid'] != exclude_itemid]\n",
    "    return recommendations.head(num_recommendations)['itemid'].tolist()\n",
    "\n",
    "# Step 3: Generate recommendations for each item\n",
    "sample_item = events_df.sample(1)  # Pick a random item a user interacted with\n",
    "sample_category = sample_item['categoryid'].values[0]\n",
    "sample_itemid = sample_item['itemid'].values[0]\n",
    "\n",
    "# Get recommendations\n",
    "recommended_items = recommend_items(sample_category, exclude_itemid=sample_itemid)\n",
    "\n",
    "print(f\"User viewed item {sample_itemid} in category {sample_category}.\")\n",
    "print(f\"Recommended items from the same category: {recommended_items}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training a full recommendation model, we'll use a User-Item Matrix and find similar users using K-Nearest Neighbors (KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:07<00:00,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for User 328227: [np.int64(247909), np.int64(285930)]\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned events data\n",
    "events_df = pd.read_csv(\"cleaned_events.csv\")\n",
    "\n",
    "# Convert event types into numerical scores (higher score for transactions)\n",
    "event_scores = {'view': 1, 'addtocart': 2, 'transaction': 5}\n",
    "events_df['rating'] = events_df['event'].map(event_scores)\n",
    "\n",
    "# Step 1: Create a Sparse User-Item Matrix\n",
    "unique_users = events_df['visitorid'].nunique()\n",
    "unique_items = events_df['itemid'].nunique()\n",
    "\n",
    "user_to_index = {user: i for i, user in enumerate(events_df['visitorid'].unique())}\n",
    "item_to_index = {item: i for i, item in enumerate(events_df['itemid'].unique())}\n",
    "index_to_item = {v: k for k, v in item_to_index.items()}  # Reverse mapping\n",
    "\n",
    "rows = events_df['visitorid'].map(user_to_index)\n",
    "cols = events_df['itemid'].map(item_to_index)\n",
    "data = events_df['rating']\n",
    "\n",
    "user_item_sparse = sparse.csr_matrix((data, (rows, cols)), shape=(unique_users, unique_items))\n",
    "\n",
    "# Step 2: Train the ALS Model\n",
    "model = AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20)\n",
    "model.fit(user_item_sparse)\n",
    "\n",
    "# Step 3: Generate Recommendations for a User\n",
    "def recommend_for_user(user_id, num_recommendations=5):\n",
    "    \"\"\" Recommend top N items for a given user \"\"\"\n",
    "    if user_id not in user_to_index:\n",
    "        return \"User not found in dataset.\"\n",
    "\n",
    "    user_idx = user_to_index[user_id]\n",
    "    recommendations = model.recommend(user_idx, user_item_sparse[user_idx], N=num_recommendations)\n",
    "\n",
    "    # Extract only integer item indices from recommendations\n",
    "    recommended_items = [index_to_item[int(i[0])] for i in recommendations]  \n",
    "\n",
    "    return recommended_items\n",
    "\n",
    "# Test Recommendation for a Random User\n",
    "sample_user = events_df['visitorid'].sample(1).values[0]\n",
    "recommended_items = recommend_for_user(sample_user)\n",
    "\n",
    "print(f\"Top recommendations for User {sample_user}: {recommended_items}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for User 342365:\n",
      "    itemid  available  categoryid\n",
      "0    5411        NaN         NaN\n",
      "1  285930        1.0         NaN\n"
     ]
    }
   ],
   "source": [
    "import pickle  # For saving the model\n",
    "\n",
    "# Load item properties\n",
    "item_properties = pd.read_csv(\"cleaned_item_properties.csv\")\n",
    "\n",
    "# Step 1: Modify Recommendation Function to Include Item Details\n",
    "def recommend_for_user(user_id, num_recommendations=5):\n",
    "    \"\"\" Recommend top N items for a given user with details \"\"\"\n",
    "    if user_id not in user_to_index:\n",
    "        return \"User not found in dataset.\"\n",
    "\n",
    "    user_idx = user_to_index[user_id]\n",
    "    recommendations = model.recommend(user_idx, user_item_sparse[user_idx], N=num_recommendations)\n",
    "\n",
    "    # Convert indices back to item IDs\n",
    "    recommended_items = [index_to_item[int(i[0])] for i in recommendations]\n",
    "\n",
    "    # Merge with item details\n",
    "    recommended_df = pd.DataFrame({'itemid': recommended_items})\n",
    "    recommended_df = recommended_df.merge(item_properties, on=\"itemid\", how=\"left\")\n",
    "\n",
    "    return recommended_df\n",
    "\n",
    "# Step 2: Save the ALS Model to a File\n",
    "with open(\"als_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Step 3: Test Enhanced Recommendation Output\n",
    "sample_user = events_df['visitorid'].sample(1).values[0]\n",
    "recommended_items = recommend_for_user(sample_user)\n",
    "\n",
    "print(f\"Top recommendations for User {sample_user}:\\n\", recommended_items)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS_virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
